
# Endpoints.md

This document describes all API endpoints exposed by the Omega-AGI FastAPI system. For each endpoint, we provide the HTTP method, path, purpose, input/output formats, validation rules, error handling details, and detailed pseudocode outlining its functions and agent interactions. All endpoints return JSON responses and are self-documented via the OpenAPI schema (accessible via the `/docs` UI).

---

## Base URL

When running locally, the base URL is typically:  
`http://localhost:8000`  
All endpoints are relative to this base URL.

---

## Summary of All Endpoints

1. **Health Check Endpoint**  
   - **GET** `/health`

2. **Omega Execution Endpoint**  
   - **POST** `/api/v1/omega`

3. **Human-to-Omega Conversion Endpoints**  
   - **LLM-based Conversion:** **POST** `/api/v1/human-to-omega/llm`  
   - **Parser-based Conversion:** **POST** `/api/v1/human-to-omega/parser`

4. **Omega Validation Endpoint**  
   - **POST** `/api/v1/omega/validate`

5. **Omega Correction Endpoint**  
   - **POST** `/api/v1/omega/correct`

6. **Omega-to-Human Translation Endpoint**  
   - **POST** `/api/v1/omega-to-human`

7. **Reasoning Endpoint**  
   - **POST** `/api/v1/omega/reasoning`

8. **Agent Processing Endpoint**  
   - **POST** `/api/v1/agent/{agent_name}/process`

9. **Reflection Endpoint**  
   - **POST** `/api/v1/omega/reflect`

10. **Improve Omega Endpoint**  
    - **POST** `/api/v1/omega/improve`

11. **Logs Retrieval Endpoint (Admin Only)**  
    - **GET** `/api/v1/logs`

---

## 1. Health Check Endpoint

**Method:** GET  
**Path:** `/health`

**Purpose:**  
Verify that the service is running.

**Request:**  
- No parameters.

**Response:**  
- **200 OK** with JSON: `{ "status": "ok" }`

**Pseudocode:**
```python
@app.get("/health")
async def health_check():
    return {"status": "ok"}
```

---

## 2. Omega Execution Endpoint

**Method:** POST  
**Path:** `/api/v1/omega`

**Purpose:**  
Process an Omega-AGI prompt by having the Omega Agent execute it via an LLM and return the result.

**Request:**  
JSON with:
- `omega` (string, required): The Omega script.
- `model` (string, optional): e.g., `"openai-gpt4"`, `"openai-gpt3.5"`, `"google-gemini"`.

**Example Request:**
```json
{
  "omega": "∇;Ω=>δ(ts='opt');DEFINE_SYMBOLS{Q=\"UserQuery\" /*Calculate 5+7*/}; → AGI_Rpt WR_SECT(Q, d=\"Compute the result.\");",
  "model": "openai-gpt3.5"
}
```

**Response:**  
JSON with:
- `result` (string): The generated output.

**Pseudocode:**
```python
@app.post("/api/v1/omega", response_model=OmegaResponse)
async def execute_omega(request: OmegaRequest):
    agent = OmegaAgent(request.omega, model=request.model or settings.default_model)
    try:
        result_text = await agent.run()  # Executes the Omega script, including any reflection/evaluation steps.
    except OmegaValidationError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception:
        raise HTTPException(status_code=500, detail="Internal error processing the request")
    await log_interaction(prompt=request.omega, response=result_text, model=request.model or settings.default_model)
    return {"result": result_text}
```

---

## 3. Human-to-Omega Conversion Endpoints

These endpoints convert natural language prompts into Omega-AGI formatted scripts.

### A. LLM-based Conversion

**Method:** POST  
**Path:** `/api/v1/human-to-omega/llm`

**Purpose:**  
Translate a natural language instruction into an Omega prompt using an LLM.

**Request:**  
JSON with:
- `human_text` (string, required)

**Example Request:**
```json
{
  "human_text": "Convert the following instruction into Omega format: Calculate the sum of 5 and 7."
}
```

**Response:**  
JSON with:
- `omega_text` (string)

**Pseudocode:**
```python
@app.post("/api/v1/human-to-omega/llm")
async def human_to_omega_llm(request: HumanToOmegaRequest):
    # Call the translator LLM function specifically for human-to-omega conversion.
    system_prompt = "You are an expert in Omega-AGI. Convert the following natural language instruction into a valid Omega prompt."
    full_prompt = f"{system_prompt}\nInstruction: {request.human_text}"
    omega_text = await call_translator_llm_human_to_omega(full_prompt)
    if not omega_text:
        raise HTTPException(status_code=500, detail="Conversion failure")
    return {"omega_text": omega_text}
```

**Instructions for `call_translator_llm_human_to_omega`:**  
- This function builds a system prompt with best practices from the Omega documentation and sends it along with the human instruction to the LLM (e.g., OpenAI 40-mini).  
- It returns the Omega script generated by the LLM.

---

### B. Parser-based Conversion

**Method:** POST  
**Path:** `/api/v1/human-to-omega/parser`

**Purpose:**  
Convert natural language to Omega format using a rule-based parser (i.e. without invoking an LLM).

**Request:**  
JSON with:
- `human_text` (string, required)

**Example Request:**
```json
{
  "human_text": "Convert: calculate the sum of 5 and 7."
}
```

**Response:**  
JSON with:
- `omega_text` (string)

**Pseudocode:**
```python
@app.post("/api/v1/human-to-omega/parser")
async def human_to_omega_parser(request: HumanToOmegaRequest):
    try:
        omega_text = rule_based_parser(request.human_text)  # See instructions below.
    except ParsingError as e:
        raise HTTPException(status_code=400, detail=str(e))
    if not omega_text:
        raise HTTPException(status_code=500, detail="Parsing failed to produce Omega output")
    return {"omega_text": omega_text}
```

**Instructions for `rule_based_parser`:**  
- This function applies pre-defined grammar rules (using regex or a lightweight parsing library) to identify key phrases in the human text and map them to Omega symbols and structure (e.g., inserting `DEFINE_SYMBOLS` and `WR_SECT` appropriately).  
- On success, it returns a valid Omega script; on failure, it raises a `ParsingError`.

---

## 4. Omega Validation Endpoint

**Method:** POST  
**Path:** `/api/v1/omega/validate`

**Purpose:**  
Check the structure and mandatory keys of an Omega script without executing it.

**Request:**  
JSON with:
- `omega` (string, required)

**Example Request:**
```json
{
  "omega": "DEFINE_SYMBOLS{Q=\"Query\"}; → AGI_Rpt WR_SECT(Q, d=\"Compute the result.\");"
}
```

**Response:**  
- On success: `{ "valid": true, "message": "Omega script is valid." }`  
- On failure: `{ "valid": false, "error": "Missing DEFINE_SYMBOLS block" }`

**Pseudocode:**
```python
@app.post("/api/v1/omega/validate")
async def validate_omega(request: OmegaValidationRequest):
    try:
        agent = OmegaAgent(request.omega, model=settings.default_model)
        agent.validate_script()  # Checks for preamble, DEFINE_SYMBOLS, WR_SECT, etc.
        return {"valid": True, "message": "Omega script is valid."}
    except OmegaValidationError as e:
        return JSONResponse(status_code=400, content={"valid": False, "error": str(e)})
```

---

## 5. Omega Correction Endpoint

**Method:** POST  
**Path:** `/api/v1/omega/correct`

**Purpose:**  
Attempt to correct an Omega script that contains errors. Uses a combination of rule‐based and LLM-based correction (with a maximum of 3 attempts).

**Request:**  
JSON with:
- `omega` (string, required)
- `attempt` (integer, optional; default 1)

**Example Request:**
```json
{
  "omega": "WRONG_SYNTAX without DEFINE_SYMBOLS",
  "attempt": 1
}
```

**Response:**  
JSON with:
- `corrected_omega` (string)
- `attempt` (integer)

**Pseudocode:**
```python
@app.post("/api/v1/omega/correct")
async def correct_omega(request: OmegaCorrectionRequest):
    max_attempts = 3
    attempt = request.attempt or 1
    agent = OmegaAgent(request.omega, model=settings.default_model)
    try:
        agent.validate_script()
        return {"corrected_omega": request.omega, "attempt": attempt}
    except OmegaValidationError as e:
        if attempt >= max_attempts:
            raise HTTPException(status_code=400, detail="Failed to correct Omega prompt after maximum attempts")
        correction_prompt = f"Detected errors: {str(e)}. Please provide a corrected Omega script for the following input:\n{request.omega}"
        corrected = await call_translator_llm_correction(correction_prompt)
        new_request = OmegaCorrectionRequest(omega=corrected, attempt=attempt+1)
        return await correct_omega(new_request)
```

**Instructions for `call_translator_llm_correction`:**  
- This function calls an LLM (with low temperature) using a correction prompt. Its role is to output a revised Omega script that fixes structural issues.
- It should be distinct from the human-to-omega translator.

---

## 6. Omega-to-Human Translation Endpoint

**Method:** POST  
**Path:** `/api/v1/omega-to-human`

**Purpose:**  
Convert an Omega script back into plain English, so users can see the human-readable version of their symbolic instructions.

**Request:**  
JSON with:
- `omega` (string, required)

**Example Request:**
```json
{
  "omega": "DEFINE_SYMBOLS{Q=\"Query\"}; → AGI_Rpt WR_SECT(Q, d=\"Compute the sum of 5 and 7.\");"
}
```

**Response:**  
JSON with:
- `human_text` (string)

**Pseudocode:**
```python
@app.post("/api/v1/omega-to-human")
async def omega_to_human(request: OmegaToHumanRequest):
    translation_prompt = f"Translate the following Omega-AGI script into plain English:\n{request.omega}"
    human_text = await call_translator_llm_omega_to_human(translation_prompt)
    if not human_text:
        raise HTTPException(status_code=500, detail="Translation failure")
    return {"human_text": human_text}
```

**Instructions for `call_translator_llm_omega_to_human`:**  
- This function instructs an LLM (using a system prompt tuned for reverse translation) to convert Omega syntax back into natural language.

---

## 7. Reasoning Endpoint

**Method:** POST  
**Path:** `/api/v1/omega/reasoning`

**Purpose:**  
Submit an Omega script to a reasoning LLM (e.g., OpenAI 03) to perform deep analysis.

**Request:**  
JSON with:
- `omega` (string, required)

**Example Request:**
```json
{
  "omega": "DEFINE_SYMBOLS{R=\"Reasoning\"}; → AGI_Rpt WR_SECT(R, d=\"Analyze potential risks of X.\");"
}
```

**Response:**  
JSON with:
- `reasoning_output` (string)

**Pseudocode:**
```python
@app.post("/api/v1/omega/reasoning")
async def reasoning(request: ReasoningRequest):
    reasoning_result = await call_reasoning_llm(request.omega)
    if not reasoning_result:
        raise HTTPException(status_code=500, detail="Reasoning failure")
    return {"reasoning_output": reasoning_result}
```

---

## 8. Agent Processing Endpoint

**Method:** POST  
**Path:** `/api/v1/agent/{agent_name}/process`

**Purpose:**  
Invoke a specific agent (each implemented as a separate module) to process an Omega script using a chain-of-thought approach.

**Request:**  
- **Path Parameter:** `agent_name` (string) – the agent identifier.
- **JSON Body:**  
  - `omega` (string, required)

**Example Request:**
```bash
curl -X POST "http://localhost:8000/api/v1/agent/agent1/process" \
  -H "Content-Type: application/json" \
  -d '{"omega": "DEFINE_SYMBOLS{A=\"Analysis\"}; → AGI_Rpt WR_SECT(A, d=\"Provide market analysis.\");"}'
```

**Response:**  
JSON with:
- `agent_response` (string)

**Pseudocode:**
```python
@app.post("/api/v1/agent/{agent_name}/process")
async def agent_process(agent_name: str, request: OmegaRequest):
    try:
        agent_module = __import__(f"agents.{agent_name}", fromlist=["process_omega"])
        agent_response = await agent_module.process_omega(request.omega)
    except Exception as exc:
        raise HTTPException(status_code=500, detail=str(exc))
    return {"agent_response": agent_response}
```

---

## 9. Reflection Endpoint

**Method:** POST  
**Path:** `/api/v1/omega/reflect`

**Purpose:**  
Evaluate an Omega script’s structure using reflection. This endpoint instructs an LLM to review the script based on best practices, assign a quality score (1–100), and provide recommendations for improvement.

**Request:**  
JSON with:
- `omega` (string, required)

**Example Request:**
```json
{
  "omega": "DEFINE_SYMBOLS{Q=\"Query\"}; → AGI_Rpt WR_SECT(Q, d=\"Compute result.\");"
}
```

**Response:**  
JSON with:
- `score` (integer, 1–100)
- `recommendations` (string): Detailed suggestions for improvement.
- `feedback` (string): A summary of the reflection.

**Pseudocode:**
```python
@app.post("/api/v1/omega/reflect")
async def reflect_omega(request: OmegaReflectionRequest):
    reflection_prompt = (
        "Review the following Omega-AGI script based on best practices. "
        "Score its structure from 1 to 100, provide detailed recommendations for improvement, "
        "and summarize your feedback.\n"
        f"Omega Script: {request.omega}"
    )
    reflection_result = await call_reflection_llm(reflection_prompt)
    if not reflection_result:
        raise HTTPException(status_code=500, detail="Reflection failure")
    # Expected reflection_result is a JSON string that includes score, recommendations, and feedback.
    return reflection_result
```

**Instructions for `call_reflection_llm`:**  
- This function sends a detailed system prompt to an LLM (configured for reflective analysis) instructing it to evaluate the Omega structure, score it, and output improvement suggestions.  
- The LLM should return a structured JSON (or parseable string) with keys: `score`, `recommendations`, and `feedback`.

---

## 10. Improve Omega Endpoint

**Method:** POST  
**Path:** `/api/v1/omega/improve`

**Purpose:**  
Improve an existing Omega script based on provided feedback and/or the score obtained from the reflection process. This endpoint calls an LLM to generate a revised version of the script.

**Request:**  
JSON with:
- `omega` (string, required): The current Omega script.
- `feedback` (string, optional): Feedback or recommendations to consider.
- `score` (integer, optional): The current score (if available).

**Example Request:**
```json
{
  "omega": "DEFINE_SYMBOLS{Q=\"Query\"}; → AGI_Rpt WR_SECT(Q, d=\"Compute result.\");",
  "feedback": "The script is missing a MEM_GRAPH and preamble for reflection.",
  "score": 65
}
```

**Response:**  
JSON with:
- `improved_omega` (string): The revised Omega script.
- `new_score` (integer, optional): A new score if the LLM re-evaluates the script.

**Pseudocode:**
```python
@app.post("/api/v1/omega/improve")
async def improve_omega(request: OmegaImproveRequest):
    improvement_prompt = (
        "Improve the following Omega-AGI script based on these recommendations. "
        "If feedback is provided, incorporate it; if a score is given, aim for a higher score.\n"
        f"Current Omega Script: {request.omega}\n"
        f"Feedback: {request.feedback or 'None'}\n"
        f"Current Score: {request.score or 'Not Provided'}\n"
        "Provide the improved Omega script."
    )
    improved_omega = await call_translator_llm_correction(improvement_prompt)
    if not improved_omega:
        raise HTTPException(status_code=500, detail="Improvement process failed")
    return {"improved_omega": improved_omega}
```

**Note:**  
- The same LLM-based correction function (`call_translator_llm_correction`) may be reused here with a specialized prompt to focus on improvement based on feedback.
- Optionally, after improvement, the client could call the reflection endpoint again to verify if the score has increased.

---

## 11. Logs Retrieval Endpoint (Admin Only)

**Method:** GET  
**Path:** `/api/v1/logs`

**Purpose:**  
Retrieve logged queries and responses from the Supabase database for monitoring and diagnostics. This endpoint is intended for administrative use only.

**Security:**  
- Requires an admin token in the header (e.g., `x-api-key`).

**Request Parameters:** (optional)
- `limit` (int): Number of records to return.
- `offset` (int): For pagination.
- `order` (string): e.g., "desc" to sort latest first.

**Response:**  
JSON array of log records, each containing:
- `id`, `prompt`, `response`, `model`, `created_at`

**Pseudocode:**
```python
@app.get("/api/v1/logs")
async def get_logs(limit: int = 20, offset: int = 0, order: str = "desc", token: str = Header(...)):
    if token != settings.admin_token:
        raise HTTPException(status_code=403, detail="Forbidden")
    logs = await fetch_logs_from_supabase(limit=limit, offset=offset, order=order)
    return logs
```

---

## Comprehensive Function Instructions

### A. `call_translator_llm` Functions

1. **`call_translator_llm_human_to_omega(prompt: str) -> str`**  
   - **Purpose:**  
     Translate human language into an Omega script.
   - **Implementation:**  
     - Prepend a system prompt that explains Omega best practices.
     - Call the LLM (e.g., OpenAI 40-mini) asynchronously.
     - Return the generated Omega text.
   - **Pseudocode:**
     ```python
     async def call_translator_llm_human_to_omega(prompt: str) -> str:
         # Build system message with instructions on converting human language to Omega.
         messages = [
             {"role": "system", "content": "You are an expert in Omega-AGI symbolic language. Convert natural language instructions into a valid Omega prompt following best practices."},
             {"role": "user", "content": prompt}
         ]
         response = await openai.ChatCompletion.acreate(model="gpt-4", messages=messages, temperature=0.2)
         return response['choices'][0]['message']['content']
     ```
2. **`call_translator_llm_omega_to_human(prompt: str) -> str`**  
   - **Purpose:**  
     Convert an Omega script into natural language.
   - **Implementation:**  
     - Prepend a system prompt instructing the LLM to “translate” the symbolic language into plain English.
     - Return the resulting human-readable text.
   - **Pseudocode:**
     ```python
     async def call_translator_llm_omega_to_human(prompt: str) -> str:
         messages = [
             {"role": "system", "content": "You are an expert in interpreting Omega-AGI scripts. Translate the following Omega script into plain, natural language."},
             {"role": "user", "content": prompt}
         ]
         response = await openai.ChatCompletion.acreate(model="gpt-4", messages=messages, temperature=0)
         return response['choices'][0]['message']['content']
     ```
3. **`call_translator_llm_correction(prompt: str) -> str`**  
   - **Purpose:**  
     Generate a corrected/improved Omega script based on a prompt that details errors or desired improvements.
   - **Implementation:**  
     - Construct a prompt explaining the errors or improvement goals.
     - Use a low-temperature setting for deterministic output.
   - **Pseudocode:**
     ```python
     async def call_translator_llm_correction(prompt: str) -> str:
         messages = [
             {"role": "system", "content": "You are an expert in Omega-AGI. Correct and improve the following Omega script based on the instructions provided."},
             {"role": "user", "content": prompt}
         ]
         response = await openai.ChatCompletion.acreate(model="gpt-4", messages=messages, temperature=0.1)
         return response['choices'][0]['message']['content']
     ```

### B. `rule_based_parser`

- **Purpose:**  
  Convert natural language to Omega script using fixed grammar rules.
- **Implementation:**  
  - Use regular expressions or simple text transformations to identify keywords.
  - Map keywords to pre-defined Omega symbols and structure.
- **Pseudocode:**
  ```python
  def rule_based_parser(human_text: str) -> str:
      # Example: Look for "calculate", "sum", "and" in human_text.
      # If found, output a simple Omega script.
      if "sum" in human_text.lower():
          # For instance, create a simple Omega script:
          return 'DEFINE_SYMBOLS{S="SumTask"}; → AGI_Rpt WR_SECT(S, d="Calculate the sum as requested.");'
      else:
          raise ParsingError("Unable to parse the input into Omega format.")
  ```

### C. Agents for Validation and Correction

- **For `/api/v1/omega/validate`:**  
  The OmegaAgent’s `validate_script()` method should:
  - Verify the presence of key elements such as preamble, `DEFINE_SYMBOLS`, and at least one `WR_SECT`.
  - Check that symbols used in instructions are defined.
  - Raise an `OmegaValidationError` with a descriptive message if any check fails.

- **For `/api/v1/omega/correct`:**  
  The agent, when catching a `OmegaValidationError`, prepares a correction prompt (see pseudocode above) and uses `call_translator_llm_correction` to generate a revised Omega script. The correction loop continues recursively until a valid script is produced or the maximum attempts (e.g., 3) are reached.
